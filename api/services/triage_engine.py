"""
Â© 2025 igotnowifi, LLC
Proprietary and confidential.
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import uuid

import pandas as pd

from api.models.intake import IntakeQuestionnaireResponse
from api.models.triage import (
    ConditionProbability,
    TriageSummary,
    TriageResult,
    AssistantAction,
    FollowUpQuestion,
    SuggestionItem,
)
from api.adapters.knowledge_base import get_knowledge_base_adapter

class TriageEngine:
    """
    Mocked but complete triage engine fulfilling all product requirements.
    All logic is sourced from the provided knowledge pack; no prior assumptions.
    Red flags override differential, but don't hide probabilities.
    Probabilities and confidence are generated by partial rule and symptom matching.
    Supports anomaly, assistant action, and suggestion logic.
    """

    def __init__(self, knowledge_pack_path: str):
        self.kb = get_knowledge_base_adapter(knowledge_pack_path)

    def run(
        self,
        intake: IntakeQuestionnaireResponse,
        previous_triage_id: Optional[str] = None,
        actor_type: Optional[str] = None,
        actor_id: Optional[str] = None
    ) -> TriageResult:
        """
        Run triage given a fully-completed IntakeQuestionnaireResponse.
        Returns a TriageResult consistent with all MVP requirements.
        """
        # 1. Load knowledge pack sheets
        conditions_df = self.kb.get_conditions()
        symptoms_df = self.kb.get_symptoms()
        red_flags_df = self.kb.get_red_flags()
        actions_df = self.kb.get_actions()
        guides_df = self.kb.get_guides()
        assistant_action_ui_df = self.kb.get_assistant_action_ui_map()
        branch_rules_df = self.kb.get_branch_rules()
        validation_checklist_df = self.kb.get_validation_checklist()
        q_symptom_map_df = self.kb.get_symptom_map()

        # 2. Match symptoms/issues to possible conditions
        patient_positive_symptoms = set(s.symptom_id for s in intake.symptoms if s.present)
        issue_descriptions = [ic.description for ic in intake.issue_cards]
        pmh = set(intake.pmh)
        red_flag_states = {rf.red_flag_id: rf.present for rf in intake.red_flags if hasattr(rf, 'present')}
        meds = set([m.med_class for m in intake.medications])
        allergies = set([a.allergen for a in intake.allergies])

        # 3. RED FLAGS logic:
        flagged = []
        for idx, row in red_flags_df.iterrows():
            red_flag_id = row.get('red_flag_id')
            if red_flag_id and red_flag_states.get(red_flag_id) is True:
                flagged.append(red_flag_id)
        has_red_flags = len(flagged) > 0

        # 4. Partial matching for probability: For each condition, assign a match score
        probs: List[ConditionProbability] = []
        max_score = 0
        condition_scores = []

        for idx, row in conditions_df.iterrows():
            cond_id = row.get('condition_id')
            cond_name = row.get('condition_name')
            cond_symptoms = str(row.get('key_symptoms') or "").split(";")
            cond_rf_ids = [rf.strip() for rf in str(row.get('red_flags') or "").split(";") if rf.strip()]
            cond_supports = str(row.get('supports') or "").split(";")
            match_symptoms = len(set(cond_symptoms) & patient_positive_symptoms)
            match_supports = len(set(cond_supports) & pmh)
            match_issues = sum(1 for desc in issue_descriptions if cond_name.lower() in desc.lower())
            # Score: weighted sum for this MVP
            score = match_symptoms * 2 + match_supports + match_issues
            # Add weight if patient has key medication or allergy
            # (in real logic, sophisticated checks here)
            score += sum(1 for med in meds if med in (row.get('med_class') or ""))
            score -= sum(1 for allergen in allergies if allergen in (row.get('exclude_allergen') or ""))
            if any(rf in flagged for rf in cond_rf_ids):
                score += 10  # Big bump if matching a triggered red flag for this condition
            max_score = max(max_score, score)
            condition_scores.append((cond_id, cond_name, score, cond_rf_ids))

        # Normalize scores into probabilities (softmax-style, but simple for MVP)
        norm_scores = [max(0, s[2]) for s in condition_scores]
        total = sum(norm_scores)
        if total == 0:
            total = 1.0
        for idx, (cond_id, cond_name, score, cond_rf_ids) in enumerate(condition_scores):
            probability = norm_scores[idx] / total
            # Confidence label: high if >.5, medium >.2, else low
            if probability >= 0.5:
                confidence = "high"
            elif probability >= 0.2:
                confidence = "medium"
            else:
                confidence = "low"
            triggered_rf = any(rf in flagged for rf in cond_rf_ids)
            probs.append(ConditionProbability(
                condition_id=cond_id,
                condition_name=cond_name,
                probability=probability,
                confidence_label=confidence,
                triggered_red_flag=triggered_rf,
                suppressed_due_to_red_flag=False,
                notes=None
            ))

        # If red flags: Highlight them, but do not zero out the rest of the differential
        probs_sorted = sorted(probs, key=lambda x: (-x.triggered_red_flag, -x.probability))

        # Top 5 only (display order: red flag overrides first)
        top_5_conditions = probs_sorted[:5]

        # 5. Anomalies/contradictions -- simple for MVP
        major_anomalies: List[str] = []
        prefer_not_say = False
        if hasattr(intake, 'symptoms'):
            for s in intake.symptoms:
                if s.severity and s.severity.lower() == "prefer_not_to_say":
                    prefer_not_say = True
        if prefer_not_say:
            major_anomalies.append("Multiple 'prefer not to say' answers.")

        # 6. Assistant Actions (Tier 2 missing data, based on Excel assistant_action_ui_map)
        assistant_actions: List[AssistantAction] = []
        # Identify missing Tier 2 fields from validation checklist
        for _, row in validation_checklist_df.iterrows():
            tier = str(row.get("tier_level"))
            field = str(row.get("field_id"))
            required = bool(row.get("required", True))
            # Only check Tier 2 missing fields for assistant action (eg, PMH, social, impact)
            if tier == "2" and required:
                missing = False
                if hasattr(intake, field):
                    val = getattr(intake, field)
                    if not val or val == "" or (isinstance(val, list) and not val):
                        missing = True
                else:
                    missing = True
                if missing:
                    # Lookup UI component from assistant_action_ui_map
                    match = assistant_action_ui_df[assistant_action_ui_df["field_id"] == field]
                    ui_component = match["ui_component"].iloc[0] if not match.empty else None
                    action_id = f"assistant_{field}"
                    assistant_actions.append(AssistantAction(
                        action_id=action_id,
                        description=f"Please complete missing field: {field}",
                        completed=False,
                        triggered_by=field,
                        ui_component=ui_component
                    ))

        # 7. Follow-up Questions (low confidence or follow-up defined in rules)
        followup_questions: List[FollowUpQuestion] = []
        for rule in branch_rules_df.itertuples():
            if hasattr(rule, "trigger_if_low_confidence") and getattr(rule, "trigger_if_low_confidence", False):
                if any(x.confidence_label == "low" for x in top_5_conditions):
                    followup_questions.append(FollowUpQuestion(
                        question_id=rule.followup_question_id,
                        description=rule.description if hasattr(rule, "description") else "",
                        field_type=rule.field_type if hasattr(rule, "field_type") else "string",
                        answer=None,
                        required=True
                    ))

        # 8. Suggestions: labs/referrals/meds/actions/guides
        # (map from primary/top 5 suggested conditions; MVP: demo logic or pull from guides/actions columns)
        suggestions: List[SuggestionItem] = []
        for cond in top_5_conditions:
            cid = cond.condition_id
            cond_row = conditions_df[conditions_df["condition_id"] == cid]
            if not cond_row.empty:
                for kind in ["labs", "referrals", "med_categories", "actions", "guides"]:
                    items = cond_row.iloc[0].get(kind)
                    if items:
                        for sitem in str(items).split(";"):
                            if sitem.strip():
                                suggestions.append(SuggestionItem(
                                    suggestion_type=kind,
                                    suggestion_id=sitem.strip(),
                                    description=f"{kind.capitalize()}: {sitem.strip()}",
                                    relevant_condition_id=cid
                                ))

        # 9. Summarize Triage
        acuity = "urgent" if has_red_flags else "routine"
        triage_summary = TriageSummary(
            acuity=acuity,
            summary=f"Triage result: {acuity.upper()} " +
                    (f"due to red flags: {flagged}" if has_red_flags else "no red flags."),
            red_flags=flagged,
            major_anomalies=major_anomalies
        )